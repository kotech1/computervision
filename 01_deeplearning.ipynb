{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_deeplearning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotech1/computervision/blob/master/01_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBg9NNbDVxbC"
      },
      "source": [
        "# Errata  \n",
        "\n",
        "본 강의 내용  중 오류 부분에 대한 수정사항입니다.   \n",
        "\n",
        "1.  1주차 1차시 Perceptron 학습 결과   \n",
        "    이 부분에서 `sign`  활성함수를 무시하겠다고 하였으나,  실제 계산은 무시하지 않고 포함하여 계산하였습니다.  \n",
        "    실제 학습 계산에 사용된 식은 다음과 같습니다.  \n",
        "$\\hat y = \\text{sign} (w_1x_1 + w_2x_2 + b)$\n",
        "\n",
        "2. 1주차 1차시 bios ==> bias 오타\n",
        "   Parameter용어 설명 중 bios는 bias의 오타입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHL6cXiXiuDs"
      },
      "source": [
        "# Perceptron의 학습\n",
        "\n",
        "실제 perceptron은 400개의 센서로 이루어져 있지만,  여기에서는 간단하게 두 개의 센서 데이터를 이용합니다.\n",
        "\n",
        "글자 '1'의 센서 데이터: $(x_1, x_2) =$ `[1, -1]`  \n",
        "글자 '0'의 센서 데이터: $(x_1, x_2) =$ `[-1, 1]`  \n",
        "\n",
        "글자 '1'의 라벨(Ground truth): $y =$ `1`  \n",
        "글자 '0'의 라벨(Ground truth): $y =$ `-1`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRMlhs7RjM1m"
      },
      "source": [
        "초기 weights 값 가정:   \n",
        "(초기 값은 임의로 주어질 수 있습니다.)  \n",
        "```\n",
        "epoch 0: w = [1, -1], b = 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXY_6X3zjfsb"
      },
      "source": [
        "**첫번째 epoch 학습:**    \n",
        "\n",
        "추론값:  \n",
        "$\\hat y = \\text{ sign }(w_1x_1+w_2x_2+b)$  \n",
        "  \n",
        "학습:  \n",
        "$w_1 = w_1 + \\eta (y-\\hat y)x_1$  \n",
        "$w_2 = w_2 + \\eta (y-\\hat y)x_2$  \n",
        "$b = b + \\eta(y-\\hat y)$  \n",
        "\n",
        "글자 `'1'`에 대한 학습: \n",
        "```\n",
        "y_hat = sign(-1*1+1*-1+0) = sign(-2) = -1 # for '1'\n",
        "w1 = -1.0 + 0.1*( 1 + 1)*1  = -0.8\n",
        "w2 =  1.0 + 0.1*( 1 + 1)*-1 =  0.8\n",
        "b  =  0.0 + 0.1*( 1 + 1)    =  0.2\n",
        "```\n",
        "글자 `'0'`에 대한 학습: \n",
        "```\n",
        "y_hat = sign(-0.8*-1+0.8*1+0.2) = sign(1.8) = 1 # for '0'\n",
        "w1 = -0.8 + 0.1*(-1 - 1)*-1 = -0.6\n",
        "w2 =  0.8 + 0.1*(-1 - 1)*1  =  0.6\n",
        "b  =  0.2 + 0.1*(-1 - 1)    =  0.0\n",
        "```\n",
        "학습 결과:  \n",
        "```\n",
        "epoch 1: w = [-0.6, 0.6], b = 0.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to_wTbDBvH2B"
      },
      "source": [
        "**이 과정을 반복하면:**  \n",
        "```\n",
        "epoch 0: w = [1, -1], b = 0.0\n",
        "epoch 1: w = [-0.6, 0.6], b = 0.0\n",
        "epoch 2: w = [-0.2, 0.2], b = 0.0\n",
        "epoch 3: w = [0.2, -0.2], b = 0.0\n",
        "epoch 4: w = [0.2, -0.2], b = 0.0 # epoch 4의 결과가 3의 결과와 동일하므로 epoch 3에서 학습이 완료되었음을 알 수 있습니다.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoh7jEiWi9uR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
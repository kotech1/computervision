{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12-deepfake.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQCLap8RwkR4if1CMhoHiF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotech1/computervision/blob/master/12_deepfake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFhvlwYw9Xv2"
      },
      "source": [
        "실습 파일: `12-deepfake.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAzGyP5M93PV"
      },
      "source": [
        "# Variational autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6RTZUli9cVd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import Dense, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Reshape, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import os\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTy6AzfxCcYH"
      },
      "source": [
        "SAVE_FOLDER = 'vae_data'\n",
        "DATA_FOLDER = SAVE_FOLDER + '/celeb/'\n",
        "\n",
        "INPUT_DIM = (128,128,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
        "\n",
        "NUM_IMAGES = len(filenames)\n",
        "\n",
        "mode =  'build' #'load' #\n",
        "#mode =  'load' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCVrMEooC_6s"
      },
      "source": [
        "**학습용 Data Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQZ3UAbjC2_9"
      },
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
        "                                         , target_size = INPUT_DIM[:2]\n",
        "                                         , batch_size = BATCH_SIZE\n",
        "                                         , shuffle = True\n",
        "                                         , class_mode = 'input'\n",
        "                                         , subset = \"training\"\n",
        "                                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA-DlvF_DG6l"
      },
      "source": [
        "**Sampling 레이어**  \n",
        "standard normal distritubion인 $\\epsilon$ 샘플링으로부터   \n",
        "$\\mu$와 $\\sigma$의 정규분포를 생성하는 레이어  \n",
        "$ N(\\mu, \\sigma) = \\mu + \\sigma N(0, 1) = \\mu + \\sigma\\epsilon$  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE77XI9lDEEt"
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (mu, log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mu, log_var = inputs\n",
        "        batch = tf.shape(mu)[0]\n",
        "        dim = tf.shape(mu)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return mu + tf.exp(log_var/2) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_dMRMWAEMZd"
      },
      "source": [
        "**Encoder 모델 정의**  \n",
        "Latent space의 차원: 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9ce9Ja0EIdE"
      },
      "source": [
        "z_dim = 200\n",
        "r_loss_factor = 10000\n",
        "\n",
        "encoder_input = keras.Input(shape=INPUT_DIM, name='encoder_input')\n",
        "x = Conv2D(32, 3, strides=2, padding=\"same\", name='encoder_conv_0')(encoder_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Conv2D(64, 3, strides=2, padding=\"same\", name='encoder_conv_1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "x = Conv2D(64, 3, strides=2, padding=\"same\", name='encoder_conv_2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "x = Conv2D(64, 3, strides=2, padding=\"same\", name='encoder_conv_3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = Flatten()(x)\n",
        "mu = Dense(z_dim, name='mu')(x)\n",
        "log_var = Dense(z_dim, name='log_var')(x)\n",
        "z = Sampling(name='encoder_output')([mu, log_var])\n",
        "encoder = keras.Model(encoder_input, [mu, log_var, z], name = 'encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PhU1L6sEY9L"
      },
      "source": [
        "**Decoder 모델 정의**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "febz8gitEdcT"
      },
      "source": [
        "decoder_input = keras.Input(shape=(z_dim,), name='decoder_input')\n",
        "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", name='decoder_conv_t0')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", name='decoder_conv_t1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "x = layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\", name='decoder_conv_t2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "x = layers.Conv2DTranspose(3, 3, strides=2, padding=\"same\", name='decoder_conv_t3')(x)\n",
        "decoder_output = Activation('sigmoid')(x)\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVJy7CBzEowy"
      },
      "source": [
        "**Variational Autoencoder 모델 정의**  \n",
        "`keras.Model` 클래스를 상속받아서 새로 정의함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7webcVhEit6"
      },
      "source": [
        "class VAEModel(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAEModel, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        #self.r_loss_factor = r_loss_factor\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.square(data - reconstruction), axis = [1,2,3]\n",
        "                #keras.losses.binary_crossentropy(data, reconstruction)\n",
        "            )\n",
        "            reconstruction_loss *= r_loss_factor\n",
        "            #reconstruction_loss *= 28 * 28\n",
        "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
        "            kl_loss *= -0.5\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": tf.reduce_mean(total_loss),\n",
        "            \"reconstruction_loss\": tf.reduce_mean(reconstruction_loss),\n",
        "            \"kl_loss\": tf.reduce_mean(kl_loss),\n",
        "        }\n",
        "\n",
        "    def call(self,inputs):\n",
        "        latent = self.encoder(inputs)\n",
        "        return self.decoder(latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeLFODApFHbA"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 200\n",
        "PRINT_EVERY_N_BATCHES = 100\n",
        "INITIAL_EPOCH = 0\n",
        "\n",
        "save_folder = os.path.join(SAVE_FOLDER, 'weights')\n",
        "\n",
        "VAE = VAEModel(encoder, decoder)\n",
        "VAE.compile(optimizer=keras.optimizers.Adam(lr=LEARNING_RATE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmFnckHzFaAO"
      },
      "source": [
        "MODE = 'build'\n",
        "#MODE = 'load'\n",
        "\n",
        "if MODE == 'load':\n",
        "    #ae = keras.models.load_model(save_folder, custom_objects={'r_loss': r_loss})\n",
        "    VAE.load_weights(save_folder+'/'+'checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMEuOxl6FkJe"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyv1zyXFh0e"
      },
      "source": [
        "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
        "    '''\n",
        "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
        "    '''\n",
        "    def schedule(epoch):\n",
        "        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
        "        return new_lr\n",
        "\n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "checkpoint = ModelCheckpoint(save_folder+'/'+'checkpoint', save_weights_only = False, verbose=1)\n",
        "lr_sched = step_decay_schedule(initial_lr=LEARNING_RATE, decay_factor=1, step_size=1)\n",
        "callbacks_list = [checkpoint, lr_sched]\n",
        "\n",
        "VAE.fit(\n",
        "    data_flow,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch = NUM_IMAGES / BATCH_SIZE,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z32J3XTFtHH"
      },
      "source": [
        "학습이 완료된 모델 weights 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lOa7McFsFu"
      },
      "source": [
        "x = np.random.rand(1,128,128,3)\n",
        "VAE.predict(x)\n",
        "VAE.save(save_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EXKBFlD97es"
      },
      "source": [
        "# Face swapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJpGTFn69---"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}